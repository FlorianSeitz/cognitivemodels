% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ebm.R
\name{gcm}
\alias{gcm}
\alias{ebmcj}
\alias{ebm}
\title{Exemplar-based Cognitive Models}
\usage{
gcm(formula, class, data, fix = NULL, options = NULL, ...)

ebmcj(formula, criterion, data, fix = NULL, options = NULL, ...)

ebm(formula, criterion, data, mode, fix = NULL, options = NULL, ...)
}
\arguments{
\item{formula}{A formula specifying  participants' responses ~ stimulus 
features (e.g., \code{y ~ f1 + f2}).}

\item{class}{A formula specifying the class feedback (e.g., \code{~ cl}), note the "\code{~}". \code{NA} values are retained, assuming a partial feedback paradigm.}

\item{data}{A data.frame containing \code{formula}'s variables.}

\item{fix}{(optional) Parameter constraints. Can be \code{"start"} or a list with \code{parname=value}-pairs. Parameter names see below under "parameter space".
\itemize{
\item{\code{"start"} constrains all available parameters to their starting values. Useful for model testing.}
\item{\code{parname = 0.5} constrains a parameter to 0.5.}
\item{\code{parname = "p2"} constrains a parameter to another model parameter \code{p2}.}
\item{\code{parname = NA} tells the model to omit a parameter, if possible.}
}}

\item{options}{(optional) Options to control the parameter fitting methods, see the "Options" section of \code{\link{cogscimodel}}.}

\item{...}{other arguments from other functions, currently ignored.}

\item{criterion}{A formula specifying the class or criterion feedback (e.g., \code{~ feedback}), note the "\code{~}".}

\item{mode}{A string. Allowed are \code{"discrete"}, \code{"continuous"}, specifies the model's response mode. Discrete responses are binary (0 or 1), continuous responses are numbers with a normal error.}
}
\value{
An exemplar-based model; a model \code{M} can be viewed with
  \code{summary(M)}, or \code{anova(M)}.
}
\description{
\code{ebm()} fits exemplar-based models, \code{gcm()} fits a generalized context model (Medin & Schaffer, 1978; Nosofsky, 1986), \code{ebmcj()} fits an exemplar-based judgment model (Juslin et al., 2003).
}
\details{
If \code{mode} is missing it will be inferred from the RHS of \code{criterion} or \code{class}.

The model can predict new data (\code{predict(M, newdata = ....)}), and this is how it works:
\itemize{
 \item{If \code{newdata}'s \code{criterion} has only \code{NA}s, the model predicts using the old data (the originally-supplied \code{data} argument) as exemplar-memory. Parameters are not re-fit.}
 \item{If \code{newdata}'s' \code{criterion} has also non-\code{NA}s, the model predicts the first new data row using the old data, but predictions for subsequent new data use also the criterion in new data. In other words, exemplar memory is \emph{extended} by exemplars in new data for which a criterion exists. Parameters are not re-fit.}
}

\code{ebmcj()} calls \link{ebm} with \code{mode = "continuous"}.

\code{gcm()} \link{ebm} with \code{mode = "discrete"}.
}
\section{Parameter Space}{

 \tabular{lrcllr}{\verb{   }
 \strong{Name} \tab \verb{   }\strong{LB} \tab  \strong{-} \tab \strong{UB}\verb{   } \tab \strong{Description} \tab \strong{Start Value} \cr\verb{   }
\code{f1, f2} \tab 0 \tab-\tab 1 \tab Attention weights, sum to 1. Note: parameter names are equal to the LHS of \code{formula} \tab 1 / n features \cr\verb{   }
\code{lambda} \tab 0.001 \tab-\tab 10 \tab Sensitivity, higher values increase the discriminability in the psychological space \tab 0.5 \cr\verb{   }
\code{q} \tab 0 \tab-\tab 2 \tab Exponent in the distance metric, 1 yields city-block, 2 yields Euclidean metric \tab 1.5 \cr\verb{   }
\code{r} \tab 0 \tab-\tab 2 \tab Exponent in the decay functio, 1 yieldes = exponential decay, 2 yields gaussian decay \tab 1.5
}
\verb{   }where \emph{LB, UB} = inclusive bounds and \emph{Start Value} = starting value for fitting.


The \code{gcm()} and \code{ebm(mode = "discrete")} have as many response bias parameters as there are category labels. For example if the categories are 0 or 1:
\verb{   }\tabular{lrcllr}{\verb{   }
 \strong{Name} \tab \verb{   }\strong{LB} \tab  \strong{-} \tab \strong{UB}\verb{   } \tab \strong{Description} \tab \strong{Start Value} \cr\verb{   }
\code{b0, b1} \tab 0 \tab-\tab 1 \tab Response bias towards each category, sum to 1. Note: names are \code{b}+unique \code{class} labels.\tab 1 / n classes
}
}

\examples{
# Make some fake data
D <- data.frame(f1 = c(0,0,1,1,2,2,0,1,2),     # feature 1
                f2 = c(0,1,2,0,1,2,0,1,2),     # feature 2
                cl = c(0,1,0,0,1,0,NA,NA,NA),  # criterion/class
                 y = c(0,0,0,1,1,1,0,1,1))     # participant's responses

M <- gcm(y ~ f1+f2, class= ~cl, D, fix="start") # GCM, par. fixed to start val.

predict(M)                                     # predict 'pred_f', pr(cl=1 | features, trial)
M$predict()                                    # -- (same) --
summary(M)                                     # summary
anova(M)                                       # anova-like table
logLik(M)                                      # Log likelihood
M$logLik()                                     # -- (same) --
M$MSE()                                        # mean-squared error
M$npar()                                       # 7 parameters
M$get_par()                                    # parameter values
M$coef()                                       # 0 free parameters


### Specify models
# -------------------------------
gcm(y ~ f1 + f2, class = ~cl, D)                    # GCM (has bias parameter)
ebm(y~f1+f2, criterion=~cl, D, mode="discrete")     # -- (same) --
ebmcj(y ~ f1 + f2, criterion = ~cl, D)              # Judgment EBM  (no bias par.)
ebm(y~f1+f2, criterion=~cl, D, mode="continuous")   # -- (same) --


### Specify parameter estimation
# -------------------------------
gcm(y~f1+f2, ~cl, D, fix="start")               # fix all par to start val. 
gcm(y~f1+f2, ~cl, D, fix=list(b0=0.5, b1=0.5))  # fix 'bias' par. to 0.5, fit 5 par
gcm(y~f1+f2, ~cl, D, fix=list(f1=0.9,f2=0.1))   # fix attention 'f1' to 90 \%  f1 & fit 5 par
gcm(y~f1+f2, ~cl, D, fix=list(q=2, r=2))        # fix 'q', 'q' to 2 & fit 5 par
gcm(y~f1+f2, ~cl, D, fix=list(q=1, r=1))        # fix 'q', 'r' to 1 & fit 5 par
gcm(y~f1+f2, ~cl, D, fix=list(lambda=2))        # fix 'lambda' to 2 & fit 6 par
gcmcj(y ~ f1 + f2, D)

}
\references{
{Medin, D. L., & Schaffer, M. M. (1978). Context theory of classification learning. \emph{Psychological Review, 85}, 207-238. \url{http://dx.doi.org/10.1037//0033-295X.85.3.207}}

{Nosofsky, R. M. (1986). Attention, similarity, and the identification-categorization relationship. \emph{Journal of Experimental Psychology: General, 115}, 39-57. \url{http://dx.doi.org/10.1037/0096-3445.115.1.39}}

{Juslin, P., Olsson, H., & Olsson, A.-C. (2003). Exemplar effects in categorization and multiple-cue judgment. \emph{Journal of Experimental Psychology: General, 132}, 133-156. \url{http://dx.doi.org/10.1037/0096-3445.132.1.133}}
}
