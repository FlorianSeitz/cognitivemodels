% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bayeslearn.R
\name{bayeslearn}
\alias{bayeslearn}
\title{Exemplar-based cognitive model}
\usage{
bayeslearn(formula, data, format = c("raw", "count"), fixed = list(),
  choicerule = NULL, response = c("continuous", "discrete"),
  discount = 0, ...)
}
\arguments{
\item{formula}{A formula specifying the variable names of response and observed events, e.g. \code{reponse ~ eventA + eventB + eventC}. Use a pipe (\code{|}) to indicate learning about more than one options, e.g. \code{reponse ~ option1_eventA + option1_eventB | option2_eventX + option2_eventY}.}

\item{data}{A data.frame or matrix containing the variables in \code{formula}; ensure it is ordered in the order in which data was seen.}

\item{format}{A string (default \code{"raw"}), specifying if data are binary indicators for observed/not observed (1=event seen, 0=event not seen) or cummulative counts of how often an outcome was observed. Allowed are \code{"raw", "count"}.}

\item{fixed}{(optional) specifies fixed parameter, to set priors for eventA and eventB use \code{fixed=list(prior.eventA=1, prior.eventB=4)}.}

\item{choicerule}{(optional) A string specifying the choice rule, allowed values see the \code{priordist} argument of \link{choicerule}. *Required* if \code{response = "discrete"} and model learns > 1 options.}

\item{response}{(optional, default \code{"continuous"}) A string specifying if beliefs are predicted (\code{"continuous"}) or if choices are predicted (\code{"discrete"}).}

\item{discount}{(optional, default 0) A number or numeric vector of trial indices to discount.}

\item{...}{other arguments from other functions, currently ignored.}
}
\value{
An model object (similar to lm-objects) of class "bayeslearn". Itcan be viewed with \code{summary(mod)}, where \code{mod} is the name of the model object.
}
\description{
Fits a Bayesian cognitive learning model. According to this model, agents update beliefs about probabilities of events in a Bayesian way given a series of observed events and prior beliefs. The model can make predictions from raw observations or relative frequencies.
}
\examples{
#  No examples yet
}
\references{
{Griffiths, T. L., & Yuille, A. (2008). Technical Introduction: A primer on probabilistic inference. In N. Chater & M. Oaksford (Eds.), The Probabilistic Mind: Prospects for Bayesian Cognitive Science (pp. 1â€“2). Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199216093.003.0002}
}
\author{
Jana B. Jarecki, \email{jj@janajarecki.com}, Markus Steiner
}
