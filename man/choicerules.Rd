% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-choicerules.R
\name{choicerules}
\alias{choicerules}
\alias{softmax}
\alias{epsilon_greedy}
\alias{epsilon}
\alias{luce}
\alias{argmax}
\title{Choicerule Models (action-selection rules)}
\usage{
softmax(formula, data, fix = list(), options = NULL)

epsilon_greedy(formula, data, fix = list(), options = NULL)

epsilon(formula, data, fix = list(), options = NULL)

luce(formula, data, ...)

argmax(formula, data, ...)
}
\arguments{
\item{formula}{A \link[stats:formula]{formula}, the variables in \code{data} to be modeled. For example, \code{y ~ x1 | x2} models response y as function of two stimuli with values x1 and x2 (respectively). Lines \code{|} separate stimuli.}

\item{data}{A data frame, the data to be modeled.}

\item{fix}{(optional) A list or the string \code{"start"}, the fixed model parameters, if missing all parameters are estimated. Model parameter names are \emph{\code{tau}} (see details - model parameters).
\itemize{
\item \code{list(tau = 3.85)} sets parameter \emph{\code{tau}} equal to 3.85.
\item \code{"start"} sets all parameters equal to their initial values (estimates none). Useful for building a first test model.
}}

\item{options}{(optional) A list to change the parameter estimation process, see \code{\link[=cm_options]{cm_options()}} or the section Options below.}
}
\value{
Returns a cognitive model object, which is an object of class \href{Cm}{cm}. A model, that has been assigned to \code{m}, can be summarized with \code{summary(m)} or \code{anova(m)}. The parameter space can be viewed using \code{parspace(m)}, constraints can be viewed using \code{constraints(m)}.
}
\description{
Models discrete action selection: applies a choce rule/decision rule/action selection rule to select among values.
\itemize{
\item \code{softmax()} fits a soft-maximum = soft approximation to argmax (Sutton & Barto, 2018).
\item \code{epsilon_greedy()} fits epsilon-greedy.
\item \code{epsilon()} fits probabilistic-epsilon.
\item \code{argmax()} maximizes deterministically.
\item \code{luce()} selects proportionally (Luce's rule aka Luce's axiom, Luce, 1959).
}
}
\details{
This is how the model predicts and treats observations:
\itemize{
\item For \code{formula = y ~ x1} and \code{y ~ x1 | x2} it predicts the probability to \strong{select x1}, thus \code{y = 1} must mean select x1.
\item For \code{formula = y ~ x1 | x2 | x3} it predicts three columns, the probabilities to select x1, x2, and x3, respectively.
}
\subsection{Model Parameters}{

Most models have no free parameters, except softmax and epsilon greedy which have 1 free parameter each:
\itemize{
\item In \code{softmax()}: \emph{\strong{\code{tau}}}: the softness of the choices, high values cause more equiprobable choices.
\item In \code{epsilon()} and \code{epsilon_greedy()}: \emph{\strong{\code{eps}}}: the error proportion of the choices, high values cause more errors.
}
}

\subsection{Background}{

\code{epsilon()} picks action \eqn{i} with probability \eqn{(1 - \epsilon)*p(i)} and with \eqn{\epsilon} it picks randomly from all actions. For \eqn{\epsilon = 0} it gives \eqn{p(i)}, that is the  original probabilistic policy.

\code{epsilon_greedy()} picks the best action with probability \eqn{1 - \epsilon}, and with \eqn{\epsilon} it picks randomly from all actions, including the best.

\code{argmax()} picks the highest-valued action with probability 1, and in case of ties it picks equiprobable.

\code{luce()} picks action \eqn{i} with probability \eqn{v(i) / \sum v}.
}

\subsection{Options}{

\verb{   } (Optional) Set \code{options} to fine-tune the parameter estimation
process. The values listed below must be supplied in list. For example
\code{options = list(lb = c(k = -10))} changes a lower parameter bound.

\describe{
\item{\verb{   }\code{lb}}{Named numeric vector, changes lower parameter bounds;
\code{lb = c(k = -10)} lets parameter \emph{k} start at -10.}
\item{\verb{   }\code{ub}}{Named numeric vector, changes upper parameter bounds:
\code{ub = c(k = 10)} lets parameter \emph{k} go until 10.}
\item{\verb{   }\code{start}}{Named numeric vector, changes parameter start
values: \code{start = c(k = 5)} lets parameter \emph{k} start at 5.}
\item{\verb{   }\code{fit}}{Logical (default \code{TRUE}), \code{fit = FALSE} disables
parameter estimation. Useful for testing models.}
\item{\verb{   }\code{fit_measure}}{A string (default \code{"loglikelihood"}), the
\href{https://en.wikipedia.org/wiki/Goodness_of_fit}{goodness of fit}
measure to be optimized during parameter estimation.
Can be any value of \code{type} in \code{\link[cognitiveutils:gof]{cognitiveutils::gof()}}.
Loglikelihood uses a binomial PDF in models with discrete
data and a normal PDF for continuous data, \eqn{N(\mu, \sigma)}
with  \eqn{\mu}=predictions, \eqn{\sigma}=constant,
estimated as additional free paramter. Change the PDF using
\code{fit_args = list(pdf = "...")}}
\item{\verb{   }\code{fit_args}}{Named list, options for parameter estimation.
Can be any
argument to \code{\link[cognitiveutils:gof]{cognitiveutils::gof()}}. For example,
\code{list(pdf = "truncnorm", a = 0, b = 1)} changes the PDF
in the log likelihood to a truncated normal between 0 and 1,
\code{list(pdf = "multinom")} changes it to a multinomial PDF.
\code{list(grid_offset = .01)} offsets the parameter in a grid search
by 0.01 from the parameter boundaries, \code{list(nsteps = 10)} defines
10 steps for each parameter in the regular grid in the grid search.}
\item{\verb{   }\code{fit_data}}{A data frame, the data to estimate the model parameters
from. Needed if the data for the parameter estimation differs from
the data in the main \code{data} argument in a model.}
\item{\verb{   }\code{solver}}{A string, the optimizer for the parameter estimation. Run
\code{cm_solvers()} to list all solvers. Can be \code{"grid"}, \code{"solnp"}
\code{"optimx"}, \code{"nloptr"}, \code{"nlminb"} and others from \link{ROI}. Can be
\code{c("grid", "xxx")}: a grid-plus-optimization: A grid search, followed
by an optimization with xxx using the \emph{n}
best solutions as start values in the optimization; the overal best
parameter set wins; and \emph{n} can be set in \code{solver_args$nbest}
Changing the solver may cause warnings and ignored parameter bounds.}
\item{\verb{   }\code{solver_args}}{A named list, additional arguments passed directly
to the solver function, see the pages of the solver to see which
arguments the solver function has. For example:
\code{list(offset = 0.01)} offset the parameters from their boundaries
when \code{solver = "grid"}.
\code{list(nsteps = 10)} uses 10 steps for each parameter in the regular
grid, for \code{solver = "grid"}), \code{list(nbest = 3)} uses the 3 best
parameter sets from the grid search as starting values in a
grid-plus-optimization solver, for \code{solver = c("grid", "xxx")}.
\code{list(control = )} control arguments in the solver
\href{Rsolnp::solnp()}{solnp} and the
\href{https://rdrr.io/cran/ROI/man/ROI_solve.html}{ROI solvers}}
}
}
}
\examples{
# Make some fake data
D <- data.frame(a = c(.3,.8,.5),       # value of option A
                b = c(.7,.2,.5),       # value of option B
                y = c(0,1,1))          # respondent's choice (0=A, 1=B)

M <- softmax(y ~ a | b, D, c(tau=1))   # creates soft-max model w tau=1

predict(M)                             # predict action selection
M$predict()                            # -- (same) --
summary(M)                             # summarize
anova(M)                               # anova-like table
coef(M)                                # free parameter (NULL)
M$get_par()                            # fixed parameter (tau = 1)
M$npar()                               # 1 parameter
M$MSE()                                # mean-squared error
logLik(M)                              # log likelihood


### Parameter specification and fitting ---------------------------------
softmax(y ~ a | b, D, fix="start")     # fix 'tau' to its start value
softmax(y ~ a | b, D, fix=c(tau=0.2))  # fix 'tau' to 0.2
softmax(y ~ a | b, D)                  # fit 'tau' to data y in D


### The different choice rules ------------------------------------------
softmax(y ~ a | b, D,  fix=c(tau=0.5)) # fix 'tau' to 0.5
softmax(y ~ a | b, D)                  # fit 'tau' to y
epsilon_greedy(y~a | b, D, c(eps=0.1)) # fix 'eps' to 10 \%
epsilon_greedy(y~a | b, D )            # fit 'eps' to y
epsilon(y ~ a | b, D, c(eps=0.1))      # fix 'eps' to 0.1
epsilon(y ~ a | b, D)                  # fit 'eps' to y
luce(y ~ a | b, D)                     # Luce's choice rule, 0 parameter
argmax(y ~ a | b, D)                   # Argmax choice rule, 0 parameter
}
\references{
Sutton, R. S., & Barto, A. G. (2018). \emph{Reinforcement Learning: An Introduction (2nd Ed.)}. MIT Press, Cambridge, MA. \link{http://incompleteideas.net/book/the-book-2nd.html}

Luce, R. D. (1959). On the possible psychophysical laws. \emph{Psychological Review, 66(2)}, 81-95. doi:\href{https://doi.org/10.1037/h0043178}{10.1037/h0043178}
}
\seealso{
Other cognitive models: 
\code{\link{baseline_const_c}()},
\code{\link{bayes}()},
\code{\link{cpt}},
\code{\link{ebm}()},
\code{\link{hm1988}()},
\code{\link{shortfall}},
\code{\link{utility}}
}
\author{
Jana B. Jarecki, \email{jj@janajarecki.com}
}
\concept{cognitive models}
