% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-bayes.R
\name{bayes}
\alias{bayes}
\alias{bayes_beta_c}
\alias{bayes_beta_d}
\alias{bayes_dirichlet_d}
\alias{bayes_dirichlet_c}
\title{Bayesian Inference Cognitive Model}
\usage{
bayes(
  formula,
  data = data.frame(),
  fix = list(),
  format = c("raw", "count", "cumulative"),
  type = NULL,
  discount = 0L,
  options = list(),
  ...
)

bayes_beta_c(
  formula,
  data,
  fix = NULL,
  format = c("raw", "count", "cumulative"),
  ...
)

bayes_beta_d(formula, data, fix = NULL, format = NULL, ...)

bayes_dirichlet_d(formula, data, fix = NULL, format = NULL, ...)

bayes_dirichlet_c(formula, data, fix = NULL, format = NULL, ...)
}
\arguments{
\item{formula}{A \href{stats::formula}{formula}, the variables in \code{data} to be modeled. For example, \code{y ~ heads + tails} models a response, \code{y}, based on events in the variables called \code{heads} and \code{tails}.}

\item{data}{A data frame.}

\item{format}{A string (default \code{"raw"}), the format of the events in \code{data}. Can be abbreviated. Allowed values:
\itemize{
\item \code{"raw"} - event variables are binary occurrence indicators for each trial (e.g., 1, 0, 1, ..., where 1 means the event happened in this trial).
\item \code{"cumulative"} - event variables are cumulative counts of events for each trial (e.g., 0, 1, 1, ..., counting how often the event happened up to this trial).
\item \code{"count"} - event variables are sum counts of events after the trials, ignoring the order of events (e.g., 2, 10, ..., where 2 indicates that in this block the event occurred 2 times, in the next block 10 times).
}}

\item{type}{(optional) A string, the type of inference, \code{"beta-binomial"} or \code{"dirichlet-multinomial"}. Can be abbreviated. Will be inferred, if missing.}

\item{options}{(optional) A list to change the parameter estimation, see \code{\link[=cm_options]{cm_options()}} or the section Options below.}
}
\value{
Returns a cognitive model object, which is an object of class \href{Cm}{cm}. A model, that has been assigned to \code{m}, can be summarized with \code{summary(m)} or \code{anova(m)}. The parameter space can be viewed using \code{parspace(m)}, constraints can be viewed using \code{constraints(m)}.
}
\description{
\code{bayes()} fits a Bayesian cognitive model, updating beliefs about the probability of discrete event outcomes based on the frequencies of outcomes.
\itemize{
\item \code{bayes_beta_c()} fits a model for 2 outcomes (beta-binomial) for continuous responses
\item \code{bayes_beta_d()} fits a model for 2 outcomes (beta-binomial) for discrete responses
\item \code{bayes_dirichlet_c()} fits a model for n outcomes (dirichlet-categorical/multinomial) for continuous responses
\item \code{bayes_dirichlet_d()} fits a model for n outcomes (dirichlet-categorical/multinomial) for discrete responses
}
}
\details{
The model models, as response variable, the belief about the occurrence of the first event in the \code{formula} as follows:
\itemize{
\item \code{y ~ a} models the beliefe about event a occurring (versus a not occurring)
\item \code{y ~ a + b} models beliefs about a occurring (versus b occurring)
\item \code{y ~ a + b + c} models beliefs about a, b, and c occurring
}
}
\section{Options}{

The following can be passed in one list, e.g. \code{options = list(lb = c(k = -10))}.

\describe{
\item{\code{lb}}{Named numeric vector, sets the lower parameter bounds;
\code{lb = c(k = -10)} lets a parameter \emph{k} start at -10.}
\item{\code{ub}}{Named numeric vector, sets the upper parameter bounds:
\code{ub = c(k = 10)} lets a parameter \emph{k} go until 10.}
\item{\code{start}}{Named numeric vector, sets the start values of parameter:
\code{start = c(k = 5)} lets a parameter \emph{k} start at 5.}
\item{\code{fit}}{Logical (default \code{TRUE}), \code{fit = FALSE} disables parameter
estimation. Useful for testing models.}
\item{\code{fit_measure}}{A string (default \code{"loglikelihood"}), the goodness
of fit measure that is optimized during parameter estimation.
Can be one of the \code{types} in the function [cognitiveutils::gof()\verb{: }"loglikelihood"\verb{. Uses a binomial PDF in models with discrete  data. Uses a normal PDF \eqn{N(\mu, \sigma)} in models with  continuous data:  \eqn{\mu}=predictions, \eqn{\sigma}=constant, estimated as additional free paramter. To change the PDF set }fit_args = list(pdf = "")}
\item{\code{fit_args}}{Named list, options for parameter estimation. Can be
arguments to the function (gof())\code{\link[cognitiveutils:gof]{cognitiveutils::gof()}}.
\code{list(pdf = "truncnorm", a = 0, b = 1)} changes the PDF
in the log likelihood to a truncated normal between 0 and 1,
\code{list(pdf = "multinom")} changes it to a multinomial PDF.
\code{list(grid_offset = .01)} offsets the parameter in a grid search
by 0.01 from the parameter boundaries, \code{list(nsteps = 10)} defines
10 steps for each parameter in the regular grid in the grid search.}
\item{\code{fit_data}}{A data frame, the data to estimate the model parameters
from. Needed if the data for the parameter estimation differs from
the data in the main \code{data} argument in a model.}
\item{\code{solver}}{A string, the optimizer for the parameter estimation. Run
\code{cm_solvers()} to list all solvers. Can be \code{"grid"}, \code{"solnp"}
\code{"optimx"}, \code{"nloptr"}, \code{"nlminb"} and others from \link{ROI}. Can be
\code{c("grid", "xxx")}: a grid-plus-optimization: A grid search, followed
by an optimization with xxx using the \emph{n}
best solutions as start values in the optimization; the overal best
parameter set wins; and \emph{n} can be set in \code{solver_args$nbest}
Changing the solver may cause warnings and ignored parameter bounds.}
\item{\code{solver_args}}{A named list, additional arguments passed directly
to the solver function, see the pages of the solver to see which
arguments the solver function has. For example:
\code{list(offset = 0.01)} offset the parameters from their boundaries
when \code{solver = "grid"}.
\code{list(nsteps = 10)} uses 10 steps for each parameter in the regular
grid, for \code{solver = "grid"}), \code{list(nbest = 3)} uses the 3 best
parameter sets from the grid search as starting values in a
grid-plus-optimization solver, for \code{solver = c("grid", "xxx")}.
\code{list(control = )} control arguments in the solver
(solnp)\code{\link[Rsolnp:solnp]{Rsolnp::solnp()}} and the
(ROI solvers)\link{https://rdrr.io/cran/ROI/man/ROI_solve.html}}
}
}

\section{Parameters}{

View the number of free parameters of a model \code{M} using \code{npar(M)} and the whole parameter space using \code{parspace(m)}. The model has n + 1 (n = number of events) free parameters, which are:
\itemize{
\item \code{delta} from 0 - 10 is the weight of one observation during learning, < 1 yields conservatism, > 1 yields liberal learning, and 1 is optimal Bayesian
\item n prior parameter named like the events, each from 0.001 - n, the prior parameter, aka. the hyperparameter of the prior belief distribution before trial 1. If they are constrainted to sum to n, n - 1 parameter are fit.
}
}

\examples{
D <- data.frame(
  a = c(0,0,1,1,1),              # event A, e.g. coin toss "heads"
  b = c(1,1,0,0,0),              # event B, complement of A
  y = c(0.5,0.3,0.2,0.3,0.5))    # participants' beliefs about A

M <- bayes_beta_c(
     formula = y ~ a + b,
     data = D)   # fit all parameters
predict(M)                        # predict posterior means
summary(M)                        # summarize model
parspace(M)                       # view parameter space
anova(M)                          # anova-like table
logLik(M)                         # loglikelihood
MSE(M)                            # mean-squared error   


# Predictions ----------------------------------------------
predict(M, type = "mean")                  # posterior mean
predict(M, type = "max")                   # maximum posterior
predict(M, type = "sd")                    # posterior SD
predict(M, type = "posteriorpar")          # posterior hyper-par.
predict(M, type = "draws", ndraws = 3)     #  --"--  3 draws


# Fix parameter ---------------------------------------------
bayes_beta_c(~a+b, D, list(delta=1, priorpar=c(1, 1)))  # delta=1, uniform prior
bayes_beta_c(~a+b, D, list(delta=1, a=1, b=1))          # -- (same) --
bayes_beta_c(~a+b, D, fix = "start")                    # fix to start values


# Parameter fitting ----------------------------------------
# Use a response variable, y, to which we fit parameter
bayes(y ~ a + b, D, fix = "start")              # "start" fixes all par., fit none 
bayes(y ~ a + b, D, fix = list(delta=1))         # fix delta, fit priors 
bayes(y ~ a + b, D, fix = list(a=1, b=1))        # fix priors, fit delta 
bayes(y ~ a + b, D, fix = list(delta=1, a=1))    # fix delta & prior on "a"
bayes(y ~ a + b, D, list(delta=1, b=1))          # fix delta & prior on "b"


### Parameter meanings
# ---------------------------------------
# delta parameter: the learning rate or evidence weight
bayes(y ~ a + b, D, c(delta = 0))             # 0   -> no learning
bayes(y ~ a + b, D, c(delta = 0.1))           # 0.1 -> slow learning
bayes(y ~ a + b, D, c(delta = 9))             # 9   -> fast learning
bayes(y ~ a + b, D, c(a=1.5, b=0.5))                # prior: a more likely
bayes(y ~ a + b, D, list(priorpar=c(1.5, 0.5)))     # -- (same) --
bayes(y ~ a + b, D, c(a = 0.1, b=1.9))              # prior: b more likely
bayes(y ~ a + b, D, list(priorpar = c(0.1, 1.9)))   # -- (same) --

}
\references{
{Griffiths, T. L., & Yuille, A. (2008). Technical Introduction: A primer on probabilistic inference. In N. Chater & M. Oaksford (Eds.), \emph{The Probabilistic Mind: Prospects for Bayesian Cognitive Science (pp. 1 - 2)}. Oxford University Press. \url{https://doi.org/10.1093/acprof:oso/9780199216093.003.0002}}

{Tauber, S., Navarro, D. J., Perfors, A., & Steyvers, M. (2017). Bayesian models of cognition revisited: Setting optimality aside and letting data drive psychological theory. \emph{Psychological Review, 124(4)}, 410 - 441. \url{http://dx.doi.org/10.1037/rev0000052}}
}
\seealso{
Other cognitive models: 
\code{\link{Cm}},
\code{\link{baseline_const_c}()},
\code{\link{gcm}()}
}
\author{
Jana B. Jarecki, Markus Steiner
}
\concept{cognitive models}
