% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-bayes.R
\name{bayes}
\alias{bayes}
\alias{bayes_beta_c}
\alias{bayes_beta_d}
\alias{bayes_dirichlet_d}
\alias{bayes_dirichlet_c}
\title{Bayesian Inference Cognitive Model}
\usage{
bayes(
  formula,
  data = data.frame(),
  fix = list(),
  format = c("raw", "count", "cumulative"),
  type = NULL,
  discount = 0L,
  options = list(),
  ...
)

bayes_beta_c(
  formula,
  data,
  fix = NULL,
  format = c("raw", "count", "cumulative"),
  ...
)

bayes_beta_d(formula, data, fix = NULL, format = NULL, ...)

bayes_dirichlet_d(formula, data, fix = NULL, format = NULL, ...)

bayes_dirichlet_c(formula, data, fix = NULL, format = NULL, ...)
}
\arguments{
\item{formula}{A \href{stats::formula}{formula}, the variables in \code{data} to be modeled. For example, \code{y ~ heads + tails} models a response, \code{y}, based on events in the variables called \code{heads} and \code{tails}.}

\item{data}{A data frame.}

\item{format}{A string (default \code{"raw"}), the format of the events in \code{data}. Can be abbreviated. Allowed values:
\itemize{
\item \code{"raw"} - event variables are binary occurrence indicators for each trial (e.g., 1, 0, 1, ..., where 1 means the event happened in this trial).
\item \code{"cumulative"} - event variables are cumulative counts of events for each trial (e.g., 0, 1, 1, ..., counting how often the event happened up to this trial).
\item \code{"count"} - event variables are sum counts of events after the trials, ignoring the order of events (e.g., 2, 10, ..., where 2 indicates that in this block the event occurred 2 times, in the next block 10 times).
}}

\item{type}{(optional) A string, the type of inference, \code{"beta-binomial"} or \code{"dirichlet-multinomial"}. Can be abbreviated. Will be inferred, if missing.}

\item{options}{(optional) A list to change the parameter estimation, see \code{\link[=cm_options]{cm_options()}} or the section Options below.}
}
\value{
Returns a cognitive model object, which is an object of class \href{Cm}{cm}. A model, that has been assigned to \code{m}, can be summarized with \code{summary(m)} or \code{anova(m)}. The parameter space can be viewed using \code{parspace(m)}, constraints can be viewed using \code{constraints(m)}.
}
\description{
\code{bayes()} fits a Bayesian cognitive model, updating beliefs about the probability of discrete event outcomes based on the frequencies of outcomes.
\itemize{
\item \code{bayes_beta_c()} fits a model for 2 outcomes (beta-binomial) for continuous responses
\item \code{bayes_beta_d()} fits a model for 2 outcomes (beta-binomial) for discrete responses
\item \code{bayes_dirichlet_c()} fits a model for n outcomes (dirichlet-categorical/multinomial) for continuous responses
\item \code{bayes_dirichlet_d()} fits a model for n outcomes (dirichlet-categorical/multinomial) for discrete responses
}
}
\details{
The model models, as response variable, the belief about the occurrence of the first event in the \code{formula} as follows:
\itemize{
\item \code{y ~ a} models the beliefe about event a occurring (versus a not occurring)
\item \code{y ~ a + b} models beliefs about a occurring (versus b occurring)
\item \code{y ~ a + b + c} models beliefs about a, b, and c occurring
}
}
\section{Options}{

The following can be passed in one list, e.g. \verb{options = list(lb = c(k = -10)). \\describe\{ \\item\{}lb\verb{\}\{Named numeric vector, sets the lower parameter bounds; }lb = c(k = -10)\verb{ lets a parameter _k_ start at -10.\} \\item\{}ub\verb{\}\{Named numeric vector, sets the upper parameter bounds: }ub = c(k = 10)\verb{ lets a parameter _k_ go until 10.\} \\item\{}start\verb{\}\{Named numeric vector, sets the start values of parameter: }start = c(k = 5)\verb{ lets a parameter _k_ start at 5.\} \\item\{}fit\verb{\}\{Logical (default }TRUE\verb{), }fit = FALSE\verb{ disables parameter estimation. Useful for testing models.\} \\item\{}fit_measure\verb{\}\{A string (default }"loglikelihood"\verb{), the goodness of fit measure that is optimized during parameter estimation. Can be one of the }types\verb{ in the function [cognitiveutils::gof()}:
\code{"loglikelihood"}. Uses a binomial PDF in models with discrete
data. Uses a normal PDF \eqn{N(\mu, \sigma)} in models with
continuous data:  \eqn{\mu}=predictions, \eqn{\sigma}=constant,
estimated as additional free paramter. To change the PDF set
\verb{fit_args = list(pdf = "")\} \\item\{}fit_args\verb{\}\{Named list, options for parameter estimation. Can be arguments to the function (gof())[cognitiveutils::gof()].  }list(pdf = "truncnorm", a = 0, b = 1)\verb{changes the PDF in the log likelihood to a truncated normal between 0 and 1,}list(pdf = "multinom")\verb{changes it to a multinomial PDF.}list(grid_offset = .01)\verb{offsets the parameter in a grid search by 0.01 from the parameter boundaries,}list(nsteps = 10)\verb{ defines 10 steps for each parameter in the regular grid in the grid search.\} \\item\{}fit_data\verb{\}\{A data frame, the data to estimate the model parameters from. Needed if the data for the parameter estimation differs from the data in the main }data\verb{ argument in a model.\} \\item\{}solver\verb{\}\{A string, the optimizer for the parameter estimation. Run }cm_solvers()\verb{to list all solvers. Can be}"grid"\verb{, }"solnp"\verb{}"optimx"\verb{, }"nloptr"\verb{, }"nlminb"\verb{and others from [ROI]. Can be}c("grid", "xxx")\verb{: a grid-plus-optimization: A grid search, followed by an optimization with xxx using the _n_ best solutions as start values in the optimization; the overal best  parameter set wins; and _n_ can be set in }solver_args$nbest\verb{ Changing the solver may cause warnings and ignored parameter bounds.\} \\item\{}solver_args\verb{\}\{A named list, additional arguments passed directly to the solver function, see the pages of the solver to see which arguments the solver function has. For example: }list(offset = 0.01)\verb{offset the parameters from their boundaries when}solver = "grid"\code{. }list(nsteps = 10)\verb{uses 10 steps for each parameter in the regular grid, for}solver = "grid"\verb{), }list(nbest = 3)\verb{uses the 3 best parameter sets from the grid search as starting values in a grid-plus-optimization solver, for}solver = c("grid", "xxx")\code{. }list(control = )` control arguments in the solver
(solnp)\code{\link[Rsolnp:solnp]{Rsolnp::solnp()}} and the
(ROI solvers)\link{https://rdrr.io/cran/ROI/man/ROI_solve.html}}
}
}

\section{Parameters}{

View the number of free parameters of a model \code{M} using \code{npar(M)} and the whole parameter space using \code{parspace(m)}. The model has n + 1 (n = number of events) free parameters, which are:
\itemize{
\item \code{delta} from 0 - 10 is the weight of one observation during learning, < 1 yields conservatism, > 1 yields liberal learning, and 1 is optimal Bayesian
\item n prior parameter named like the events, each from 0.001 - n, the prior parameter, aka. the hyperparameter of the prior belief distribution before trial 1. If they are constrainted to sum to n, n - 1 parameter are fit.
}
}

\examples{
D <- data.frame(
  a = c(0,0,1,1,1),              # event A, e.g. coin toss "heads"
  b = c(1,1,0,0,0),              # event B, complement of A
  y = c(0.5,0.3,0.2,0.3,0.5))    # participants' beliefs about A

M <- bayes_beta_c(
     formula = y ~ a + b,
     data = D)   # fit all parameters
predict(M)                        # predict posterior means
summary(M)                        # summarize model
parspace(M)                       # view parameter space
anova(M)                          # anova-like table
logLik(M)                         # loglikelihood
MSE(M)                            # mean-squared error   


# Predictions ----------------------------------------------
predict(M, type = "mean")                  # posterior mean
predict(M, type = "max")                   # maximum posterior
predict(M, type = "sd")                    # posterior SD
predict(M, type = "posteriorpar")          # posterior hyper-par.
predict(M, type = "draws", ndraws = 3)     #  --"--  3 draws


# Fix parameter ---------------------------------------------
bayes_beta_c(~a+b, D, list(delta=1, priorpar=c(1, 1)))  # delta=1, uniform prior
bayes_beta_c(~a+b, D, list(delta=1, a=1, b=1))          # -- (same) --
bayes_beta_c(~a+b, D, fix = "start")                    # fix to start values


# Parameter fitting ----------------------------------------
# Use a response variable, y, to which we fit parameter
bayes(y ~ a + b, D, fix = "start")              # "start" fixes all par., fit none 
bayes(y ~ a + b, D, fix = list(delta=1))         # fix delta, fit priors 
bayes(y ~ a + b, D, fix = list(a=1, b=1))        # fix priors, fit delta 
bayes(y ~ a + b, D, fix = list(delta=1, a=1))    # fix delta & prior on "a"
bayes(y ~ a + b, D, list(delta=1, b=1))          # fix delta & prior on "b"


### Parameter meanings
# ---------------------------------------
# delta parameter: the learning rate or evidence weight
bayes(y ~ a + b, D, c(delta = 0))             # 0   -> no learning
bayes(y ~ a + b, D, c(delta = 0.1))           # 0.1 -> slow learning
bayes(y ~ a + b, D, c(delta = 9))             # 9   -> fast learning
bayes(y ~ a + b, D, c(a=1.5, b=0.5))                # prior: a more likely
bayes(y ~ a + b, D, list(priorpar=c(1.5, 0.5)))     # -- (same) --
bayes(y ~ a + b, D, c(a = 0.1, b=1.9))              # prior: b more likely
bayes(y ~ a + b, D, list(priorpar = c(0.1, 1.9)))   # -- (same) --

}
\references{
{Griffiths, T. L., & Yuille, A. (2008). Technical Introduction: A primer on probabilistic inference. In N. Chater & M. Oaksford (Eds.), \emph{The Probabilistic Mind: Prospects for Bayesian Cognitive Science (pp. 1 - 2)}. Oxford University Press. \url{https://doi.org/10.1093/acprof:oso/9780199216093.003.0002}}

{Tauber, S., Navarro, D. J., Perfors, A., & Steyvers, M. (2017). Bayesian models of cognition revisited: Setting optimality aside and letting data drive psychological theory. \emph{Psychological Review, 124(4)}, 410 - 441. \url{http://dx.doi.org/10.1037/rev0000052}}
}
\seealso{
Other cognitive models: 
\code{\link{Cm}},
\code{\link{baseline_const_c}()}
}
\author{
Jana B. Jarecki, Markus Steiner
}
\concept{cognitive models}
