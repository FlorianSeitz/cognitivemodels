% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hm1988.R
\name{hm1988}
\alias{hm1988}
\title{Houston & McNamara's (1988) dynamic optimization model for risk-sensitive foraging problems in discrete time}
\usage{
hm1988(
  formula,
  state,
  budget,
  trial,
  ntrials,
  initstate,
  data,
  choicerule,
  fix = list(),
  options = NULL,
  fitnessfun = NULL
)
}
\arguments{
\item{formula}{(optional) object of class \link[stats]{formula}, e.g. \code{choice ~ timehorizon + state}, defines how the variables are called in the data.}

\item{data}{(optional) data frame}

\item{env}{object of class \link{rsenvironment}, see example. It specifies the risky and safe option, the number of trials, the state, and requirement (aka budget).}
}
\value{
An object of class R6 holding the model, it has no free parameters. A model object \code{M} can be viewed with \code{M}, predictions can be made with \code{M$predict()} for choice predictions, and \code{M$predict("ev")} for the expected value of the optimal choice and \code{M$predict("value", 1:2)} for the expected value of all choices.
}
\description{
Houston & McNamara's (1988) dynamic optimization model for risk-sensitive foraging problems in discrete time
}
\details{
Risk-sensitive foraging means you have, for instance, four choices between the same two risky lotteries and after the four choices you need to have accumulated at least 12 points to get a reward. The optimal solution to this choice problem relies on dynamic programming. The function creates all possible future states given the possible remaining trials, and predicts the optimal choice polica or the expected value of chosing either option given a certain state and a certain time horizon.
}
\examples{
# define the the environment like this:
###    requirement: budget = 12
###    number of choices: n.trials = 4
###    initial number of points: initial.state = 10
###    risky option: a1, with three outcomes
###    safe option: a2, with three outcomes
env <- rsenvironment(budget = 12,
                     n.trials = 4,
                     initial.state = 10,
                     a1 = matrix(c(0.1, 0.8, 0.1, 0, 1, 2), nc = 2),
                     a2 = matrix(c(0.4, 0.2, 0.4, 0, 1, 2), nc = 2))
# check the environment
env
# > env
# Reach 12 in 4 trials with options:
#     a1 (0, 0.1) or (1, 0.8) or (2, 0.1) 
#     a2 (0, 0.4) or (1, 0.2) or (2, 0.4) 
#
# Initial state of 10

# Run the optimal model
M <- hm1988(env = env, ~ timehorizon + state, choicerule = "arg")

# Results:
M # view model
M$input # view all possible state + trial combinations
M$predict() # optimal mode for all possible state x trial combinations
cbind(M$input, M$predict())
M$predict("mode") # optimal mode
M$predict("ev") # expected value of optimal choice for all possible states and trials
M$predict("value") # expected value of choice a1
M$predict("value", 1:2) # expected value of a1 or a2

# Predict specific state x trial scenarios for 1 ... 4 trials left and a state of 11
newdt <-  data.frame(timehorizon = 1:4, state = 11)
M$predict("v", newdata = newdt, 1:2)
M$predict("r", newdata = newdt)

}
\references{
Houston, A. I., & McNamara, J. M. (1988). A framework for the functional analysis of behaviour. Behavioural and Brain Science, 11, 117â€“163.
}
\author{
Jana B. Jarecki, \email{jj@janajarecki.com}
}
